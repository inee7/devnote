---
tags: [cache, redis, memcached, distributed-cache, performance, network-bandwidth]
---

## 한 줄 요약

분산 캐시는 반드시 운영 환경 기준 성능 테스트를 수행하여 네트워크 대역폭과 캐시 히트율을 함께 고려해야 한다.

## 핵심 정리

- 분산 캐시 도입 전 성능 테스트 필수
- 캐시 히트율이 높아도 네트워크 대역폭 부족하면 오히려 느려짐
- 데이터 크기가 클수록 네트워크 대역폭 영향 큼
- 대규모 이벤트 시 캐시 동시 갱신으로 대역폭 폭증 주의
- 캐시 필드 선택을 신중히 (필요한 필드만 캐싱)

## 상세 내용

### 분산 캐시의 함정

#### 캐시 히트율만으로는 부족하다

**일반적인 오해**

```
캐시 히트율 90% = 성능 10배 향상?
→ 실제로는 더 느려질 수 있음!
```

이유:
- 캐시 서버(Redis, Memcached)는 네트워크로 통신
- 네트워크 대역폭이 부족하면 병목
- 로컬 메모리보다 훨씬 느림

#### 네트워크 대역폭 문제

**문제 상황**

```kotlin
// 사용자 객체를 통째로 캐싱
data class User(
    val id: Long,
    val name: String,
    val email: String,
    val profileImage: ByteArray,  // 수 MB 크기!
    val settings: String,  // JSON 문자열, 수십 KB
    val history: List<OrderHistory>  // 수백 개
)

@Cacheable("users")
fun getUser(userId: Long): User {
    return userRepository.findById(userId).orElseThrow()
}
```

문제:
- 한 번의 캐시 조회에 수 MB 데이터 전송
- 초당 수천 건 요청 시 네트워크 대역폭 고갈
- 캐시 조회가 DB 조회보다 느려짐

**해결: 필요한 필드만 캐싱**

```kotlin
data class UserCache(
    val id: Long,
    val name: String,
    val email: String
    // profileImage, history 등 제외
)

@Cacheable("users")
fun getUserCache(userId: Long): UserCache {
    val user = userRepository.findById(userId).orElseThrow()
    return UserCache(
        id = user.id,
        name = user.name,
        email = user.email
    )
}
```

### 네트워크 대역폭의 이해

#### 통신마다 대역폭 할당

**대역폭 경합**

```
서버 ↔ Redis 간 네트워크 대역폭: 1Gbps

각 요청이 1MB 데이터를 가져온다면:
→ 1Gbps = 125MB/s
→ 초당 최대 125개 요청만 처리 가능
```

통신이 매우 잦으면:
- 대역폭 할당 경합 증가
- 패킷 지연, 재전송 발생
- 전체 처리량 감소

#### 실제 측정 필요

**성능 테스트 시나리오**

```kotlin
@Test
fun `분산 캐시 성능 테스트`() {
    val iterations = 10000
    val data = createLargeData()  // 실제 운영 데이터 크기

    // 1. 로컬 메모리 캐시
    val localCacheTime = measureTimeMillis {
        repeat(iterations) {
            localCache.get(key)
        }
    }

    // 2. Redis 캐시
    val redisCacheTime = measureTimeMillis {
        repeat(iterations) {
            redisTemplate.opsForValue().get(key)
        }
    }

    // 3. DB 직접 조회
    val dbTime = measureTimeMillis {
        repeat(iterations) {
            repository.findById(id)
        }
    }

    println("Local Cache: ${localCacheTime}ms")
    println("Redis Cache: ${redisCacheTime}ms")
    println("DB: ${dbTime}ms")

    // Redis가 더 느리면 분산 캐시 부적합
    assertTrue(redisCacheTime < dbTime)
}
```

측정 포인트:
- 다양한 데이터 크기
- 동시 요청 수
- 네트워크 지연 시간
- 피크 타임 트래픽

### 대규모 이벤트와 캐시

#### 캐시 갱신 폭주

**문제 상황**

```kotlin
// 상품 정보 캐싱 (TTL 1시간)
@Cacheable(value = "products", key = "#productId")
fun getProduct(productId: Long): Product {
    return productRepository.findById(productId).orElseThrow()
}
```

대규모 이벤트 시작 (예: 12시 정각):
1. 수만 명이 동시에 상품 조회
2. 캐시 TTL 만료로 대부분 캐시 미스
3. 모든 요청이 DB 접근 → Cache Stampede
4. 새로 캐싱된 대용량 데이터가 동시에 네트워크 전송
5. 네트워크 대역폭 폭증

**해결 1: Cache Warming**

```kotlin
@Scheduled(cron = "0 55 * * * *")  // 이벤트 5분 전
fun warmupCache() {
    val popularProducts = productRepository.findPopularProducts()

    popularProducts.forEach { product ->
        // 미리 캐시에 적재
        redisTemplate.opsForValue().set(
            "products::${product.id}",
            product,
            1.hours
        )
    }
}
```

**해결 2: Stale-While-Revalidate**

```kotlin
fun getProduct(productId: Long): Product {
    val cacheKey = "products::$productId"

    // 캐시 조회
    val cached = redisTemplate.opsForValue().get(cacheKey)
    if (cached != null) {
        return cached
    }

    // 락을 걸고 단 하나의 요청만 DB 조회
    val lockKey = "lock::$cacheKey"
    val acquired = redisTemplate.opsForValue()
        .setIfAbsent(lockKey, "locked", 10.seconds)

    return if (acquired == true) {
        try {
            val product = productRepository.findById(productId).orElseThrow()
            redisTemplate.opsForValue().set(cacheKey, product, 1.hours)
            product
        } finally {
            redisTemplate.delete(lockKey)
        }
    } else {
        // 다른 요청이 DB 조회 중이면 잠시 대기 후 재시도
        Thread.sleep(100)
        redisTemplate.opsForValue().get(cacheKey)
            ?: productRepository.findById(productId).orElseThrow()
    }
}
```

### 캐시 필드 선택 전략

#### 캐싱 대상 결정 기준

**캐싱하면 좋은 데이터**
- 읽기 빈도 높음
- 쓰기 빈도 낮음
- 데이터 크기 작음 (수십 KB 이하)
- 일관성 요구 낮음 (약간의 지연 허용)

**캐싱하면 안 되는 데이터**
- 실시간 정합성 필수 (잔액, 재고 등)
- 데이터 크기 매우 큼 (MB 단위)
- 사용자마다 다른 데이터 (개인화)
- 쓰기 빈도 높음 (캐시 무효화 빈번)

#### 필드 선택 전략

**나쁜 예: 전체 캐싱**

```kotlin
@Cacheable("products")
fun getProduct(id: Long): Product {
    // 모든 필드 포함 → 수 MB
    return productRepository.findById(id).orElseThrow()
}
```

**좋은 예: 필요한 필드만**

```kotlin
data class ProductSummary(
    val id: Long,
    val name: String,
    val price: BigDecimal,
    val stock: Int
    // 상세 설명, 이미지 등 제외
)

@Cacheable("product-summaries")
fun getProductSummary(id: Long): ProductSummary {
    val product = productRepository.findById(id).orElseThrow()
    return ProductSummary(
        id = product.id,
        name = product.name,
        price = product.price,
        stock = product.stock
    )
}
```

#### 계층적 캐싱

```kotlin
// 1단계: 작은 요약 정보 (Redis)
@Cacheable("product-summaries")
fun getProductSummary(id: Long): ProductSummary

// 2단계: 전체 정보 (로컬 캐시 or DB)
fun getProductDetail(id: Long): Product {
    return localCache.get(id) {
        productRepository.findById(id).orElseThrow()
    }
}
```

자주 조회되는 요약 정보만 Redis에 캐싱하고,
상세 정보는 로컬 캐시나 DB에서 조회

### 성능 테스트 시나리오

#### 실제 운영 환경 기준 테스트

**체크리스트**

1. **데이터 크기 측정**
   ```kotlin
   val serialized = objectMapper.writeValueAsBytes(cachedObject)
   println("Cache size: ${serialized.size} bytes")
   ```

2. **네트워크 대역폭 확인**
   - 서버 ↔ Redis 간 대역폭
   - 피크 타임 트래픽 예상치
   - 여유 대역폭 확보 여부

3. **부하 테스트**
   ```kotlin
   // Gatling, JMeter 등 사용
   scenario("캐시 조회")
       .exec(http("get product")
           .get("/products/1"))
       .pause(1)

   setUp(
       scenario.inject(
           rampUsers(1000).during(60.seconds)
       )
   )
   ```

4. **모니터링 메트릭**
   - 캐시 히트율
   - 평균 응답 시간
   - 네트워크 사용량 (bytes/sec)
   - Redis CPU/메모리 사용률

## 실무 적용

### 도입 전 체크리스트

- [ ] 캐싱할 데이터의 평균 크기는?
- [ ] 초당 캐시 조회 수는?
- [ ] 네트워크 대역폭 충분한가?
- [ ] 피크 타임 트래픽 감당 가능한가?
- [ ] 캐시 히트율 목표는?
- [ ] 로컬 캐시 대비 이점이 명확한가?

### 모니터링 필수 지표

```kotlin
@Component
class CacheMetrics(
    private val meterRegistry: MeterRegistry
) {
    fun recordCacheAccess(
        cacheName: String,
        hit: Boolean,
        dataSize: Int,
        duration: Duration
    ) {
        meterRegistry.counter(
            "cache.access",
            "cache", cacheName,
            "hit", hit.toString()
        ).increment()

        meterRegistry.summary(
            "cache.data.size",
            "cache", cacheName
        ).record(dataSize.toDouble())

        meterRegistry.timer(
            "cache.access.time",
            "cache", cacheName
        ).record(duration)
    }
}
```

모니터링:
- 캐시 히트율 (목표: 80% 이상)
- 평균 응답 시간 (목표: DB 조회보다 빠름)
- 네트워크 사용량 (대역폭의 70% 이하 유지)
- 데이터 크기 분포

### 금융권에서의 고려사항

- 캐시 장애 시 즉시 DB로 폴백 (캐시는 선택, DB는 필수)
- 민감한 데이터는 암호화하여 캐싱
- 캐시 TTL을 비즈니스 요구사항에 맞게 설정 (너무 길면 정합성 문제)
- Redis Cluster 구성으로 단일 장애점 제거
- 성능 테스트는 운영 데이터 기준으로 (테스트 데이터는 부정확)

---

**출처**
- 요즘 우아한 개발 (우아한형제들 기술블로그)
