---
tags: [운영, 모니터링, 배치, 그라파나, 백엔드]
---

## 한 줄 요약

운영 환경에서는 프로필 격리, 배치 모니터링, 어드민 시스템으로 안정성과 가시성을 확보한다.

## 핵심 정리

- 로컬 환경에서 운영 프로필 실행 방지 (MQ, DB 오염 위험)
- 배치 작업은 Grafana/InfluxDB로 모니터링
- 데이터 변경이 잦으면 어드민 시스템 구축
- 환경 변수와 프로필로 환경 분리
- 모든 운영 작업은 로그와 알림 필수

## 상세 내용

### 환경 격리

#### 로컬에서 운영 프로필 실행 방지

**실제 사고 사례**

```bash
# 로컬에서 실수로 운영 프로필 실행
$ java -jar app.jar --spring.profiles.active=prod
```

결과:
- 로컬 애플리케이션이 운영 DB에 연결
- 운영 MQ의 메시지를 소비 (중복 처리, 메시지 유실)
- 테스트 데이터가 운영 DB에 삽입
- 운영 데이터 오염

#### 환경 검증 로직

**방법 1: 프로필 검증 필터**

```kotlin
@Configuration
class EnvironmentValidator : ApplicationListener<ApplicationReadyEvent> {

    @Value("\${spring.profiles.active:default}")
    private lateinit var activeProfile: String

    override fun onApplicationEvent(event: ApplicationReadyEvent) {
        val hostname = InetAddress.getLocalHost().hostName
        val env = System.getenv("DEPLOYMENT_ENV")

        // 로컬/개발 환경 판별
        val isLocalOrDev = hostname.contains("local") ||
                          hostname.contains("dev") ||
                          hostname.contains("localhost")

        // 운영 프로필 사용 중인데 로컬/개발 환경이면 차단
        if (activeProfile in listOf("prod", "production") && isLocalOrDev) {
            logger.error("Cannot run production profile on local/dev environment!")
            logger.error("Hostname: $hostname, Profile: $activeProfile")
            throw IllegalStateException(
                "Production profile is not allowed on local/dev environment"
            )
        }

        // 환경 변수 검증
        if (activeProfile == "prod" && env != "PRODUCTION") {
            throw IllegalStateException(
                "prod profile requires DEPLOYMENT_ENV=PRODUCTION environment variable"
            )
        }

        logger.info("Environment validation passed: $hostname, $activeProfile")
    }
}
```

**방법 2: 프로필별 설정 분리**

```yaml
# application-local.yml
spring:
  kafka:
    bootstrap-servers: localhost:9092
  datasource:
    url: jdbc:h2:mem:testdb

# application-dev.yml
spring:
  kafka:
    bootstrap-servers: dev-kafka:9092
  datasource:
    url: jdbc:mysql://dev-db:3306/myapp

# application-prod.yml (환경 변수로만 설정)
spring:
  kafka:
    bootstrap-servers: ${KAFKA_SERVERS}  # 환경 변수 필수
  datasource:
    url: ${DB_URL}
```

운영 설정은 환경 변수 의존:
- 로컬에서는 환경 변수 없어서 실행 불가
- 운영 서버에만 환경 변수 설정

#### MQ Consumer 환경별 격리

```kotlin
@Configuration
class KafkaConsumerConfig {

    @Value("\${spring.profiles.active:default}")
    private lateinit var activeProfile: String

    @Bean
    fun kafkaListenerContainerFactory(): ConcurrentKafkaListenerContainerFactory<String, String> {
        val factory = ConcurrentKafkaListenerContainerFactory<String, String>()

        // 로컬/개발 환경에서는 특정 토픽만 구독
        if (activeProfile in listOf("local", "dev")) {
            factory.setRecordFilterStrategy { record ->
                // dev 토픽만 허용
                !record.topic().startsWith("dev-")
            }
        }

        return factory
    }
}
```

### 배치 작업 모니터링

#### 배치 실행 확인의 어려움

**문제**
- 배치는 주로 새벽에 실행
- 실패해도 즉시 알기 어려움
- 로그 확인하려면 서버 접속 필요

**해결: Grafana + InfluxDB**

#### 배치 메트릭 수집

```kotlin
@Component
class BatchMetrics(
    private val meterRegistry: MeterRegistry
) {
    fun recordBatchExecution(
        batchName: String,
        success: Boolean,
        duration: Duration,
        processedCount: Int
    ) {
        // 성공/실패 카운터
        meterRegistry.counter(
            "batch.execution",
            "batch", batchName,
            "success", success.toString()
        ).increment()

        // 실행 시간
        meterRegistry.timer(
            "batch.duration",
            "batch", batchName
        ).record(duration)

        // 처리 건수
        meterRegistry.gauge(
            "batch.processed.count",
            Tags.of("batch", batchName),
            processedCount
        )

        // 실패 시 알림
        if (!success) {
            sendAlert(batchName)
        }
    }

    private fun sendAlert(batchName: String) {
        // Slack, Email 등으로 알림
    }
}
```

#### 배치 래퍼

```kotlin
@Component
class BatchExecutor(
    private val batchMetrics: BatchMetrics
) {
    fun <T> execute(
        batchName: String,
        task: () -> T
    ): T {
        val startTime = Instant.now()
        var success = false
        var result: T? = null

        try {
            logger.info("[$batchName] Starting batch...")
            result = task()
            success = true
            logger.info("[$batchName] Batch completed successfully")
            return result!!
        } catch (e: Exception) {
            logger.error("[$batchName] Batch failed", e)
            throw e
        } finally {
            val duration = Duration.between(startTime, Instant.now())
            batchMetrics.recordBatchExecution(
                batchName = batchName,
                success = success,
                duration = duration,
                processedCount = (result as? List<*>)?.size ?: 0
            )
        }
    }
}

// 사용 예
@Scheduled(cron = "0 0 2 * * *")
fun dailySettlement() {
    batchExecutor.execute("daily-settlement") {
        settlementService.process()
    }
}
```

#### Grafana 대시보드 구성

**메트릭 시각화**

```
[배치 실행 현황]
- 배치별 성공/실패 건수 (막대 그래프)
- 배치별 평균 실행 시간 (라인 그래프)
- 최근 실패한 배치 목록 (테이블)

[알림 규칙]
- 배치 실패 시 즉시 Slack 알림
- 실행 시간이 평소보다 2배 이상 걸리면 알림
- 처리 건수가 평소보다 50% 이하면 알림
```

InfluxDB 쿼리 예시:
```sql
SELECT
    count(*) as executions,
    sum(case when success='true' then 1 else 0 end) as successes,
    sum(case when success='false' then 1 else 0 end) as failures
FROM batch_execution
WHERE time > now() - 24h
GROUP BY batch
```

### 어드민 시스템 구축

#### 데이터 변경 시나리오

**안티패턴: 개발자가 직접 DB 쿼리**

```sql
-- 운영 DB에 직접 접속해서 실행
UPDATE users SET points = points + 1000 WHERE id = 12345;
```

문제:
- 감사 로그 없음
- 실수 위험 (WHERE 조건 누락 등)
- 롤백 어려움
- 누가 언제 왜 변경했는지 추적 불가

#### 어드민 시스템 구축

**기본 구조**

```kotlin
@RestController
@RequestMapping("/admin/api")
@PreAuthorize("hasRole('ADMIN')")
class AdminApiController(
    private val adminService: AdminService,
    private val auditLogger: AuditLogger
) {

    @PostMapping("/users/{userId}/points/adjust")
    fun adjustUserPoints(
        @PathVariable userId: Long,
        @RequestBody request: AdjustPointsRequest,
        @AuthenticationPrincipal admin: AdminUser
    ): ApiResponse<User> {
        // 1. 감사 로그 기록
        auditLogger.log(
            admin = admin,
            action = "ADJUST_POINTS",
            target = "USER:$userId",
            before = userService.getPoints(userId),
            after = userService.getPoints(userId) + request.amount,
            reason = request.reason,
            ipAddress = request.remoteAddr
        )

        // 2. 작업 수행
        val result = adminService.adjustPoints(userId, request.amount)

        // 3. 알림 (중요한 작업일 경우)
        if (abs(request.amount) > 10000) {
            slackNotifier.send(
                "High-value points adjustment: " +
                "${request.amount} points for user $userId by ${admin.name}"
            )
        }

        return ApiResponse.success(result)
    }
}
```

**감사 로그**

```kotlin
@Entity
@Table(
    name = "admin_audit_log",
    indexes = [
        Index(name = "idx_admin_id", columnList = "admin_id"),
        Index(name = "idx_created_at", columnList = "created_at"),
        Index(name = "idx_action", columnList = "action")
    ]
)
class AdminAuditLog(
    @Id @GeneratedValue
    val id: Long = 0,

    val adminId: Long,
    val adminName: String,
    val adminEmail: String,

    val action: String,  // ADJUST_POINTS, UPDATE_USER, DELETE_ORDER 등
    val target: String,  // USER:123, ORDER:456 등

    @Column(columnDefinition = "TEXT")
    val beforeValue: String?,

    @Column(columnDefinition = "TEXT")
    val afterValue: String?,

    @Column(columnDefinition = "TEXT")
    val reason: String,  // 작업 사유

    val ipAddress: String,
    val userAgent: String,

    @Column(nullable = false, updatable = false)
    val createdAt: LocalDateTime = LocalDateTime.now()
)
```

#### 어드민 UI 구성

**주요 기능**

1. **사용자 검색 및 관리**
   - 이메일, 전화번호, ID로 검색
   - 포인트 조정
   - 계정 상태 변경 (활성/정지)

2. **주문 관리**
   - 주문 취소
   - 환불 처리
   - 배송 상태 변경

3. **배치 작업 관리**
   - 배치 수동 실행
   - 배치 실행 이력 조회
   - 실패한 배치 재실행

4. **감사 로그 조회**
   - 어드민 작업 이력 조회
   - 특정 사용자에 대한 변경 이력
   - 의심스러운 작업 필터링

### 모니터링 전략

#### 핵심 메트릭

**애플리케이션 메트릭**
```kotlin
@Component
class ApplicationMetrics {
    @Scheduled(fixedDelay = 60000)
    fun recordMetrics() {
        // JVM 메트릭
        meterRegistry.gauge("jvm.memory.used", Runtime.getRuntime().totalMemory())
        meterRegistry.gauge("jvm.memory.max", Runtime.getRuntime().maxMemory())

        // 비즈니스 메트릭
        meterRegistry.gauge("active.users", userService.getActiveUserCount())
        meterRegistry.gauge("pending.orders", orderService.getPendingOrderCount())
    }
}
```

**알림 규칙 설정**

```yaml
# Grafana Alert Rules
alerts:
  - name: High Error Rate
    condition: error_rate > 5%
    for: 5m
    notify: slack-channel

  - name: Slow Response Time
    condition: p95_response_time > 3s
    for: 10m
    notify: slack-channel

  - name: Batch Failure
    condition: batch_failure_count > 0
    notify: slack-channel, pagerduty
```

## 실무 적용

### 운영 체크리스트

**배포 전**
- [ ] 환경 검증 로직이 있는가?
- [ ] 프로필별 설정이 분리되어 있는가?
- [ ] 민감한 설정은 환경 변수로 관리하는가?

**배치 작업**
- [ ] 모든 배치에 메트릭 수집이 있는가?
- [ ] Grafana 대시보드가 구성되어 있는가?
- [ ] 실패 시 알림이 가는가?

**어드민 시스템**
- [ ] 감사 로그를 남기는가?
- [ ] 중요한 작업은 추가 인증을 요구하는가?
- [ ] IP 화이트리스트가 설정되어 있는가?

**모니터링**
- [ ] 핵심 메트릭이 수집되는가?
- [ ] 알림 규칙이 설정되어 있는가?
- [ ] On-call 담당자가 지정되어 있는가?

### 장애 대응 프로세스

**1. 장애 감지**
- Grafana 알림 → Slack
- PagerDuty로 On-call 담당자에게 알림

**2. 초기 대응**
- 영향 범위 파악 (어떤 기능이 영향받는가?)
- 긴급 조치 (서비스 중단 vs 부분 차단 vs 롤백)

**3. 원인 분석**
- 로그 확인
- 메트릭 분석
- 최근 배포/설정 변경 확인

**4. 복구**
- 롤백 or 핫픽스
- 모니터링으로 복구 확인

**5. 사후 분석**
- 포스트모텀 작성
- 재발 방지 대책 수립

### 금융권에서의 고려사항

- 환경 격리는 네트워크 레벨에서도 수행 (VPC, 방화벽)
- 배치 작업 실패 시 자동 재시도 금지 (수동 확인 후 재실행)
- 어드민 작업은 이중 인증 + IP 화이트리스트
- 감사 로그는 변경 불가능한 저장소에 보관 (S3 Glacier 등)
- 모든 데이터 변경은 승인 프로세스 필수

---

**출처**
- 요즘 우아한 개발 (우아한형제들 기술블로그)
